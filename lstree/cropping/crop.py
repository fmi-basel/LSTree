from multiprocessing import Pool
import luigi
import os
import pandas as pd
import logging

from improc.roi import padded_crop
from lstree.luigi_utils import ExternalInputFile


class CropMovieTask(luigi.Task):
    '''
    Crops objects from a lightsheet movie with pre-computed bounding boxes.
    
    If multiple objects are passed, the frames are only loaded once.
    '''

    out_directory = luigi.Parameter(
        description='base output directory for processed outputs')
    data_collection = luigi.Parameter(
        description='path to h5 file generated by the object detection output')
    objects_csv = luigi.ListParameter(
        description=
        'csv files of bound boxes generated by the crop reviewer gui')
    frame_memory = luigi.IntParameter(
        2000, description="estimated memory usage per frame in MB")
    n_threads = luigi.IntParameter(
        16, description='max number of threads for pre/post processing')

    @property
    def resources(self):
        resources = super().resources
        resources.update({
            'memory': self.frame_memory * self.n_threads,
            'pool_workers': self.n_threads
        })
        return resources

    def requires(self):
        return {
            'dc':
            ExternalInputFile(path=self.data_collection),
            'csvs': [
                ExternalInputFile(path=os.path.join(self.out_directory, o))
                for o in self.objects_csv
            ],
        }

    def output(self):

        out_subdirs = [os.path.splitext(o)[0] for o in self.objects_csv]
        return [
            luigi.LocalTarget(path=os.path.join(self.out_directory, subdir))
            for subdir in out_subdirs
        ]

    def _crop_img(self, packed_params):

        (_, row_in), (_, rows_out) = packed_params

        logger = logging.getLogger('luigi-interface')

        # ingore existing file
        if all([os.path.isfile(p) for p in rows_out.dc.path]):
            logger.info(
                'Cropping: skipping {}, output(s) already exist'.format(
                    row_in.dc.path[0]))
            return

        logger.info('Cropping: {}'.format(row_in.dc.path[0]))

        img = row_in.dc.read()[0]

        for _, row in rows_out.reset_index().iterrows():
            z_slice = slice(int(row.z_start_movie), int(row.z_stop_movie))
            x_slice = slice(int(row.x_start_movie), int(row.x_stop_movie))
            y_slice = slice(int(row.y_start_movie), int(row.y_stop_movie))

            bb = (z_slice, x_slice, y_slice)
            row.dc.write(padded_crop(img, bb), compress=6, bigtiff=True)

    def run(self):

        df = pd.read_hdf(self.input()['dc'].path, key='dc')

        # build the output dataframe with all combination of channel and object
        df_out = []
        for in_target, out_target in zip(self.input()['csvs'], self.output()):
            obj_out = df.copy().reset_index()
            obj_out['basedir'] = out_target.path + '_in_progress'

            obj_crop = pd.read_csv(in_target.path).set_index('time')
            df_out.append(
                pd.concat(
                    [obj_out.set_index('time'), obj_crop.loc[obj_out.time]],
                    axis=1))

        df_out = pd.concat(df_out).reset_index()

        # goupby time and channel --> crop multiple objects from the same stack at once (if any)
        with Pool(processes=self.n_threads) as pool:
            r = list(
                pool.imap(
                    self._crop_img,
                    zip(df.groupby(['time', 'channel']),
                        df_out.groupby(['time', 'channel']))))

        # finally rename folders containing output
        for out_target in self.output():
            os.rename(out_target.path + '_in_progress', out_target.path)
