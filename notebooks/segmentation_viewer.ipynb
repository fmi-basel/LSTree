{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from improc.io import parse_collection, DCAccessor\n",
    "DCAccessor.register()\n",
    "from holoviews import opts\n",
    "import holoviews as hv\n",
    "\n",
    "from inter_view.dashboards import SegmentationDashBoard, DashBoardCallback\n",
    "\n",
    "hv.extension('bokeh', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '../data'\n",
    "\n",
    "data_pattern = '{dataset_id}/{layer}/{fname_head}T{time:04d}.{ext}'\n",
    "index = ['dataset_id', 'layer', 'time', 'fname_head']\n",
    "\n",
    "nuclei_ch = 'Channel1-Deconv'\n",
    "cell_ch = 'Channel0-Deconv'\n",
    "nuclei_seg = 'nuclei_segmentation'\n",
    "cell_seg = 'cell_segmentation'\n",
    "lumen_seg = 'lumen_segmentation'\n",
    "\n",
    "channel_config = {cell_ch:{'cmap':'red'},#, 'intensity_bounds':(1000,20000), 'slider_limits':(0,60000)},\n",
    "                  nuclei_ch:{'cmap':'gray'},#, 'intensity_bounds':(300,15000), 'slider_limits':(0,60000)},\n",
    "                  nuclei_seg:{'cmap':'glasbey_hv_16bit', 'raster_aggregator':'first', 'intensity_bounds':(0,2**16-1), 'bitdepth':16, 'opacity':0.2},\n",
    "                  cell_seg:{'cmap':'glasbey_hv_16bit', 'raster_aggregator':'first', 'intensity_bounds':(0,2**16-1), 'bitdepth':16, 'opacity':0.2},\n",
    "                  lumen_seg:{'cmap':'glasbey_hv_16bit', 'raster_aggregator':'first', 'intensity_bounds':(0,2**16-1), 'bitdepth':16, 'opacity':0.2}}\n",
    "\n",
    "opts.defaults(opts.Image('channel.{}'.format(cell_seg), clipping_colors={'min': (0, 0, 0, 0)}, clim=(1,256*256-1), tools=['hover']),\n",
    "              opts.Image('channel.{}'.format(nuclei_seg), clipping_colors={'min': (0, 0, 0, 0)}, clim=(1,256*256-1), tools=['hover']),\n",
    "              opts.Image('channel.{}'.format(lumen_seg), clipping_colors={'min': (0, 0, 0, 0)}, clim=(1,256*256-1), tools=['hover']))\n",
    "\n",
    "opts.defaults(opts.Image('channel', frame_width=1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_collection(os.path.join(basedir, data_pattern), index)\n",
    "df = df.dc[:,[nuclei_ch, cell_ch, nuclei_seg, cell_seg, lumen_seg]]\n",
    "df = df.reset_index('fname_head')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interactive dashboard\n",
    "\n",
    "- ctrl + click to select the layers to overlay\n",
    "- Use the export button to copy the currently loaded nuclei|lumen segmentation in a correction subfolder --> use the 3D_annotator notebook to correct the segmentation labels for retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "    \n",
    "class SegmentationCallbackDashBoard(SegmentationDashBoard, DashBoardCallback):\n",
    "    ''''''\n",
    "\n",
    "    @param.depends('_complete_update_counter')\n",
    "    def widgets(self):\n",
    "        wg = [super().widgets(), self._export_widgets()]\n",
    "        return pn.Column(*wg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "def copy_nuclei_for_corrections(db):\n",
    "    subdf = db.subdf.reset_index().set_index('layer').dc[nuclei_seg]\n",
    "    \n",
    "    subdf_out = subdf.copy().reset_index()\n",
    "    subdf_out.layer = 'nuclei_corrections'\n",
    "    \n",
    "    # save labels as signed int16\n",
    "    pred = subdf.dc.read()[0]\n",
    "    subdf_out.dc.write(pred.astype(np.int16), compress=9, exist_ok=True)\n",
    "copy_nuclei_for_corrections.name = 'copy nuclei for corrections'\n",
    "\n",
    "def copy_lumen_for_corrections(db):\n",
    "    subdf = db.subdf.reset_index().set_index('layer').dc[lumen_seg]\n",
    "    \n",
    "    subdf_out = subdf.copy().reset_index()\n",
    "    subdf_out.layer = 'lumen_corrections'\n",
    "    \n",
    "    # save labels as signed int16\n",
    "    pred = subdf.dc.read()[0]\n",
    "    subdf_out.dc.write(pred.astype(np.int16), compress=9, exist_ok=True)\n",
    "copy_lumen_for_corrections.name = 'copy lumen for corrections'\n",
    "\n",
    "db = SegmentationCallbackDashBoard(df=df,\n",
    "                                   multi_select_levels=['layer'],\n",
    "                                   channel_config=channel_config,\n",
    "                                   composite_channels=[nuclei_ch, cell_ch],\n",
    "                                   overlay_channels=[nuclei_seg, cell_seg, lumen_seg],\n",
    "                                   export_funs=[copy_nuclei_for_corrections,\n",
    "                                                copy_lumen_for_corrections])\n",
    "\n",
    "# disable cell and lumen segmentation by default\n",
    "db.io_widgets()[1].value = [nuclei_ch, cell_ch, nuclei_seg]\n",
    "\n",
    "db.panel().servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scratch]",
   "language": "python",
   "name": "conda-env-scratch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
