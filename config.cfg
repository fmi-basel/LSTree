# General ##############################################################
[DEFAULT]
pattern={subdir}/{fname}-T{time:04d}.{ext}

### Important points:
# set the same default number of threads of all multithreaded tasks
# when processing a single dataset use n_threads ~= number of cores
# Note that some tasks actually use multiprocessing when internal operations do not release the GIL
#~n_threads=8
# For all instances of 'movie_dirs' please provide a list of full paths to the corresponding channel folders containing the datasets, following the folder structure described in the Readme.

[resources]
gpu=1
pool_workers=16
memory=64000

[core]
workers=16
log_level=INFO
outdir = ./

# Denoising/Deconvolution ##############################################
[BuildDenoiseTrainingRecordTask]
training_base_dir=models/denoise
base_dir=data/
n_images=30
train_fraction=0.9
valid_fraction=0.1
min_patch_size=(512,512)

[DenoiseTrainingTask]
training_base_dir=models/denoise
base_dir=data/
images_dirs=["*/Channel0", "*/Channel1", "*/Channel2"]

downsampling_factor=(4,)
n_downsampling_channels=16
n_groups=8
dilation_rates=(1, 2, 4)
channels_per_group=32
n_steps=5
dropout=0.1

train_batch_size=16
valid_batch_size=32
epochs=200
n_restarts=5
learning_rate=0.0001
patch_size=(128,128,1)
suffix=20200311

# If a specific model needs to be retrained, or if a training stopped due to an error and needs to be continued, one can resume the weights based on "weights_latest.h5" or "weights_best.h5" from the previous model by uncommenting below.

#resume_weights=PATH_TO_CURRENT_MODEL/weights_latest.h5

intensity_offset_sigma=0.5
intensity_scaling_bounds=(0.1, 10.)

[ChannelBoundsTask]


[DenoiseTask]
out_suffix=-Denoised

[DeconvolutionTask]
psf_dir=models/deconv/20190830
out_suffix=-Deconv
niter=128
#~max_patch_size=(512,512,512)
max_patch_size=(9999,9999,9999)


[MultiDeconvolutionTask]
ch_subdirs=["Channel0", "Channel1", "Channel2"]
movie_dirs=["/example/data/*-*"]

# Lineage ##############################################################
[TreePropsTask]
out_subdir=tree_props
xml_tree=mamut_deconv.xml

# Nuclei segmentation ##################################################
[BuildNucleiTrainingRecordTask]
training_base_dir=models/nuclei_seg
ch_subdir=Channel1
annot_subdir=nuclei_annot
spacing=(2,0.26,0.26)
train_fraction=0.9
valid_fraction=0.1
min_patch_size=(32,256,256)
patch_margins=(6,40,40)

[BuildWeakNucleiTrainingRecordTask]
training_base_dir=models/nuclei_seg
ch_subdir=Channel1
spacing=(2,0.26,0.26)
train_fraction=1.
valid_fraction=0.
min_patch_size=(32,256,256)
patch_margins=(6,40,40)

[NucleiWeakAnnotTask]
ch_subdir=Channel1
out_subdir=nuclei_weak_annot

[NucleiSegmentationTrainingTask]
training_base_dir=models/nuclei_seg
movie_dirs=["/example/data/*-*"]

downsampling_factor=(1,8,8)
n_downsampling_channels=32
n_groups=4
dilation_rates=(1, 2, 4, 8)
channels_per_group=32
n_steps=5
dropout=0.1
n_classes=2
spacing=(2,0.26,0.26)

train_batch_size=4
train_batches_per_epoch=200
valid_batch_size=8
epochs=300
n_restarts=5
learning_rate=0.0001
patch_size=(24,192,192,1)
suffix=20210227

intra_margin=2.0
inter_margin=6.0
jaccard_hinge=0.3
jaccard_eps=0.1

# If a specific model needs to be retrained, or if a training stopped due to an error and needs to be continued, one can resume the weights based on "weights_latest.h5" or "weights_best.h5" from the previous model by uncommenting below.

#resume_weights=PATH_TO_CURRENT_MODEL/weights_latest.h5

intensity_offset_sigma=0.5
intensity_scaling_bounds=(0.1, 10.)

[NucleiSegmentationTask]
ch_subdir=Channel1
out_subdir=nuclei_segmentation

[MultiNucleiSegmentationTask]
movie_dirs=["/example/data/*-*"]

# Cell segmentation ##################################################
[BuildLumenTrainingRecordTask]
training_base_dir=models/cell_seg
ch_subdir=Channel0
annot_subdir=lumen_annot
spacing=(2,0.26,0.26)
train_fraction=0.9
valid_fraction=0.1
min_patch_size=(32,256,256)
patch_margins=(12,80,80)

[BuildWeakCellTrainingRecordTask]
training_base_dir=models/cell_seg
ch_subdir=Channel0
spacing=(2,0.26,0.26)
train_fraction=0.9
valid_fraction=0.1
min_patch_size=(32,256,256)
patch_margins=(6,40,40)

[CellSegmentationTrainingTask]
training_base_dir=models/cell_seg
movie_dirs_lumen=["/example/data/*-*"]
movie_dirs_cell=["/example/data/*-*"]

downsampling_factor=(1,8,8)
n_downsampling_channels=32
n_groups=4
dilation_rates=(1, 2, 4, 8)
channels_per_group=32
n_steps=5
dropout=0.1
n_classes=3
spacing=(2,0.26,0.26)

train_batch_size=8
train_batches_per_epoch=200
valid_batch_size=32
epochs=200
n_restarts=5
learning_rate=0.0001
patch_size=(24,192,192,1)
suffix=20210227

intra_margin=2.0
inter_margin=6.0
jaccard_hinge=0.3
jaccard_eps=1.0

# If a specific model needs to be retrained, or if a training stopped due to an error and needs to be continued, one can resume the weights based on "weights_latest.h5" or "weights_best.h5" from the previous model by uncommenting below.

#resume_weights=PATH_TO_CURRENT_MODEL/weights_latest.h5

intensity_offset_sigma=0.5
intensity_scaling_bounds=(0.1, 10.)

[CellSegmentationTask]
ch_subdir=Channel0
out_subdir_lumen=lumen_segmentation
out_subdir_cell=cell_segmentation

[MultiCellSegmentationTask]
movie_dirs=["/example/data/*-*"]

# Features #############################################################
[ExtractFeaturesTask]
out_subdir=features
nuclei_subdir=Channel1

[MultiAggregateFeaturesTask]
# datasets to process that are tracked
movie_dirs=["/example/data/*-*"]


[MultiAggregateOrganoidFeaturesTask]
# datasets to process that are not tracked (lumen/organoid volume only)
movie_dirs=[]


# meshes ###############################################################
[SegmentationMeshTask]

[VolumeGridTask]
raw_channel_subdirs=["Channel1", "Channel0"]
ref_mesh_subdir=cell_mesh
colormaps=["gray", "red"]
blending_mode=max

out_subdir=rgb_grid

[ViewerTask]
movie_dirs=["/example/data/*-*"]
nuclei_seg_subdir=nuclei_segmentation
cell_seg_subdir=cell_segmentation

# tracking #############################################################
[BuildTrackingTrainingRecordTask]
training_base_dir=models/tracking
ch_subdir=Channel1
spacing=(2,0.26,0.26)
train_fraction=0.95
valid_fraction=0.05
min_patch_size=(32,256,256,2)
patch_margins=(3,24,24,0)
xml_tree=mamut_deconv.xml

[TrackingTrainingTask]
plot_dataset=true
training_base_dir=models/tracking
movie_dirs=["/example/data/*-*"]


downsampling_factor=(1,8,8)
n_downsampling_channels=64
n_groups=4
dilation_rates=(1, 2, 4, 8)
channels_per_group=64
n_steps=6
dropout=0.1
n_classes=2
spacing=(2,0.26,0.26)

train_batch_size=1
train_batches_per_epoch=200
valid_batch_size=8
epochs=3000
n_restarts=5
learning_rate=0.0001
patch_size=(24,192,192,-1)
suffix=20210306

intra_margin=2.0
inter_margin=6.0
jaccard_hinge=0.3
jaccard_eps=0.1

# If a specific model needs to be retrained, or if a training stopped due to an error and needs to be continued, one can resume the weights based on "weights_latest.h5" or "weights_best.h5" from the previous model by uncommenting below.

#resume_weights=PATH_TO_CURRENT_MODEL/weights_latest.h5

intensity_offset_sigma=0.5
intensity_scaling_bounds=(0.1, 10.)

[NucleiTrackingTask]
ch_subdir=Channel1
out_subdir_nuclei=track_nuclei
out_subdir_link=track_link
out_subdir_score=track_score

[ExtractTrackingFeaturesTask]
out_subdir=track_props

[BuildTreeTask]
xml_bdv=dataset_deconv.xml
max_n_nuclei = 256
min_track_length = 0

[MultiBuildTreeTask]
movie_dirs=["/example/data/*-*"]

